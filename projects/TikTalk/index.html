<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="TeViS                             .hidden.menu {       display: none;     }      .masthead.segment {       min-height: 700px;       padding: 0em 0em;  &#x2F;* munu padding *&#x2F;     }">
<meta property="og:type" content="website">
<meta property="og:title" content="AIMind">
<meta property="og:url" content="http://example.com/projects/TikTalk/index.html">
<meta property="og:site_name" content="AIMind">
<meta property="og:description" content="TeViS                             .hidden.menu {       display: none;     }      .masthead.segment {       min-height: 700px;       padding: 0em 0em;  &#x2F;* munu padding *&#x2F;     }">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/projects/TikTalk/assets/img/dataset.png">
<meta property="og:image" content="http://example.com/projects/TikTalk/assets/img/dataset_tab.png">
<meta property="og:image" content="http://example.com/projects/TikTalk/assets/img/model.png">
<meta property="og:image" content="http://example.com/projects/TikTalk/assets/img/clip_baseline.png">
<meta property="og:image" content="http://example.com/projects/TikTalk/assets/img/res.png">
<meta property="og:image" content="http://example.com/projects/TikTalk/assets/img/task_all.png">
<meta property="article:published_time" content="2023-08-03T14:22:23.875Z">
<meta property="article:modified_time" content="2023-08-03T14:22:23.875Z">
<meta property="article:author" content="AIMind All rights Reserved.">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/projects/TikTalk/assets/img/dataset.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>AIMind</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 5.4.2"></head>

<body class="max-width mx-auto px3 ltr">
    
    <div class="content index py4">
        
          <header id="header">
  <a href="/">
  
    
      <div id="logo" style="background-image: url(/images/logo.png);"></div>
    
  
    <div id="title">
      <h1>AIMind <div id="at">@RUC</div></h1>
    </div>
  </a>
  <div id="nav">
    <ul>
      <li class="icon">
        <a href="#" aria-label="Menu"><i class="fas fa-bars fa-2x"></i></a>
      </li>
      
        
        <li>
          <a href="/">
            Home
            
          </a>
        </li>
      
   
        
        <li>
          <a href="/team/">
            Team
            
          </a>
        </li>
      
   
        
        <li>
          <a href="/publications">
            Publications
            
          </a>
        </li>
      
   
        
        <li>
          <a href="/projects/">
            Projects
            
          </a>
        </li>
      
   
        
   
        
        <li>
          <a target="_blank" rel="noopener" href="https://gpt.by-pro.cn/">
            chatbot
            
              <i class="fas fa-robot"></i>
              
          </a>
        </li>
      
   
    </ul>
  </div>
</header>

        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  

  <div class="content" itemprop="articleBody">
      
          <!DOCTYPE html>
<html>

<head>
  <!-- Standard Meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <!-- Site Properties -->
  <title>TeViS</title>

  <!-- You MUST include jQuery before Fomantic -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/fomantic-ui@2.8.8/dist/semantic.min.css">
  <script src="https://cdn.jsdelivr.net/npm/fomantic-ui@2.8.8/dist/semantic.min.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <style type="text/css">
    .hidden.menu {
      display: none;
    }

    .masthead.segment {
      min-height: 700px;
      padding: 0em 0em;  /* munu padding */
    }

    .masthead .logo.item img {
      margin-right: 1em;
    }

    .masthead .ui.menu .ui.button {
      margin-left: 0.5em;
    }

    .masthead h1.ui.header {
      margin-top: 3em;
      margin-bottom: 0em;
      font-size: 4em;
      font-weight: normal;
    }

    .masthead h2 {
      font-size: 1.7em;
      font-weight: normal;
    }

     .ui.vertical.stripe {
      padding: 8em 0em;
    }

    .ui.vertical.stripe h3 {
      font-size: 2em;
    }

    .ui.vertical.stripe .button+h3,
    .ui.vertical.stripe p+h3 {
      margin-top: 3em;
    }

    .ui.vertical.stripe .floated.image {
      clear: both;
    }

    .ui.vertical.stripe p {
      font-size: 1.33em;
    }

    .ui.vertical.stripe .horizontal.divider {
      margin: 3em 0em;
    }

    .quote.stripe.segment {
      padding: 0em;
    }

    .quote.stripe.segment .grid .column {
      padding-top: 5em;
      padding-bottom: 5em;
    }

    .footer.segment {
      padding: 5em 0em;
    }

    .secondary.pointing.menu .toc.item {
      display: none;
    }

    @media only screen and (max-width: 700px) {
      .ui.fixed.menu {
        display: none !important;
      }

      .secondary.pointing.menu .item,
      .secondary.pointing.menu .menu {
        display: none;
      }

      .secondary.pointing.menu .toc.item {
        display: block;
      }

      .masthead.segment {
        min-height: 350px;
      }

      .masthead h1.ui.header {
        font-size: 2em;
        margin-top: 1.5em;
      }

      .masthead h2 {
        margin-top: 0.5em;
        font-size: 1.5em;
      }
    }

    p {
      text-align: justify;
      font-size: 12pt;
    }

    .masthead {
      background-image: url('assets/img/bg.png') !important;
      background-size: cover !important;
    }

    .masthead.segment {
      min-height: 300px;
    }

    .masthead h1.ui.header {
      margin-top: 0em;
    }

    .masthead .ui.tex a {
      margin-bottom: 40px;
    }

    .masthead a {
      color: #EEE;
    }

    .ui.vertical.stripe.segment {
      padding: 5em 0em;
    }
  </style>

  <script>
    $(document)
      .ready(function () {

        // fix menu when passed
        $('.masthead')
          .visibility({
            once: false,
            onBottomPassed: function () {
              $('.fixed.menu').transition('fade in');
            },
            onBottomPassedReverse: function () {
              $('.fixed.menu').transition('fade out');
            }
          })
          ;

        // create sidebar and attach to menu open
        $('.ui.sidebar')
          .sidebar('attach events', '.toc.item')
          ;

      })
      ;
  </script>
</head>

<body>

  <!-- Menu -->
  <div class="ui large top fixed hidden menu" style="background-color:rgb(224, 224, 229);">
    <div class="ui container">
      <a href="tiktalk.html" class="active item"><i class="home icon"></i>Home</a>
      <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2301.05880" class="item"><i class="book icon"></i>arXiv</a>
      <a href="#bib" data-target="#bib" class="item"><i class="quote right icon"></i>BibTeX</a>
      <a target="_blank" rel="noopener" href="https://github.com/RUC-AIMind/TikTalk" class="item"><i class="align database icon"></i>Dataset</a>
      <a target="_blank" rel="noopener" href="https://github.com/RUC-AIMind/TikTalk" class="item"><i class="github icon"></i>GitHub</a>
    </div>
  </div>

  <!-- Sidebar Menu -->
  <div class="ui vertical inverted sidebar menu">
    <a href="tiktalk.html" class="active item">
      <i class="home icon"></i>Home
    </a>


  </div>


  <!-- Page Contents -->
  <div class="pusher" >
    <div class="ui inverted vertical masthead center aligned segment">
      <div class="ui large secondary inverted pointing menu" style="background-color:#373435ff;">
        <div class="ui container">
          <a class="toc item">
            <i class="sidebar icon"></i>
          </a>
          <a href="tiktalk.html" class="active item">
            <i class="home icon"></i>Home
          </a>
        </div>
      </div>

      <div class="ui  text container" style="background-color: rgba(255,255,255,0.3); ">
        <h1 class="ui inverted header" style="color: #000000;">
          TikTalk
        </h1>
        <h2 style="color: #000000;">
          A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World
        </h2>
        <h4 style="color: #000000;">
          <a href="" style="color: #000000;">Hongpeng Lin</a>&nbsp;<sup>1</sup>,
          <a href="" style="color: #000000;">Ludan Ruan</a>&nbsp;<sup>2</sup>,
          <a href="" style="color: #000000;">Wenke Xia</a>&nbsp;<sup>1</sup>,
          <a href="" style="color: #000000;">Peiyu Liu</a>&nbsp;<sup>1</sup>,
          <a href="" style="color: #000000;">Jingyuan Wen</a>&nbsp;<sup>1</sup>,
          <a href="" style="color: #000000;">Yixin Xu</a>&nbsp;<sup>1</sup>,
          <a href="" style="color: #000000;">Di Hu</a>&nbsp;<sup>1</sup>,
          <a href="" style="color: #000000;">Ruihua Song</a>&nbsp;<sup>1</sup>,
          <a href="" style="color: #000000;">Wayne Xin Zhao</a>&nbsp;<sup>1</sup>,
          <a href="" style="color: #000000;">Qin Jin</a>&nbsp;<sup>2</sup>,
          <a href="" style="color: #000000;">Zhiwu Lu</a>&nbsp;<sup>1</sup>,</a>
        </h4>
        <h4 style="color: #000000;">
          <sup>1</sup> <a target="_blank" rel="noopener" href="http://ai.ruc.edu.cn/english/" style="color: #000000;"> Gaoling School of Artificial Intelligence, Renmin University of China</a>,
          <sup>2</sup> <a target="_blank" rel="noopener" href="http://info.ruc.edu.cn/Home/index.htm" style="color: #000000;"> School of Information, Renmin University of China</a>,
        </h4>

        <div class="ui center aligned container segment" style="background-color:transparent;">
          <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2301.05880" class="ui primary small labeled icon button" ><i class="align book icon"></i>arXiv</a>
          <a href="#bib" class="ui primary small labeled icon button"><i class="align quote right icon"></i>BibTeX</a>
          <a target="_blank" rel="noopener" href="https://github.com/RUC-AIMind/TikTalk" class="ui primary small labeled icon button"><i class="align database icon"></i>Dataset</a>
          <a target="_blank" rel="noopener" href="https://github.com/RUC-AIMind/TikTalk" class="ui primary small labeled icon button"><i class="align github icon"></i>GitHub</a>
        </div>
        
      </div>
    </div>
    
    <div class="ui vertical stripe segment" id="motivation">
      <div class="ui middle aligned stackable grid container">       

        <div class="row">
          <div class="eighteen wide column">
            <h3 class="ui header">
              <div class="ui blue horizontal big label">
                Task Definition
              </div>
              What is TeViS Task? &ensp; &#127916;<!-- <em data-emoji=':film_frames:'></em> -->
            </h3>
            <p>
              A storyboard is a roadmap for video creation which consists of shot-by-shot images to visualize key plots in a text synopsis. 
              Creating video storyboards however remains challenging which not only requires association between high-level texts and images, 
              but also demands for long-term reasoning to make transitions smooth across shots. 
              We propose a new task called Text synopsis to Video Storyboard (TeViS), 
              which aims to retrieve an ordered sequence of images to visualize the text synopsis. <br/>

              Previous works on text-to-image retrieval can only produce static images without considering the dynamics of shots in the video. 
              Text-to-video works are able to retrieve or generate videos. 
              Yet, most of them focus on short-term video clips with only a few seconds as shown in Fig. 1 (a). 
              The images in these videos are highly redundant and cannot satisfy the requirement of a video storyboard for coherent keyframes. 
              Previous works on visual storytelling works are proposed to visualize text with a sequence of images, 
              but they care more about the text-image relevancy while omitting long-term reasoning to make transition smooth across keyframes (see Fig. 1 (b)). 
              Moreover, the query texts in existing works are visually concrete and descriptive, 
              making the models less generalizable to more abstract and high-level text synopses such as the synopsis in Fig. 1 (c).
            </p>
            <img class="ui fluid image" src="assets/img/dataset.png" width="80%" />
          </div>
        </div>

        <div class="row">
          <div class="eighteen wide column">
            <h3 class="ui header">
              <div class="ui blue horizontal big label">
                Dataset
              </div>
              What is <a target="_blank" rel="noopener" href="https://ruc-aimind.github.io/projects/tevis.html">MovieNet-TeViS</a> Dataset?&ensp;
            </h3>
            <p>
              In the TeViS task, we aim to retrieve an ordered sequence of 
              images from large-scale movie database as video
              storyboard to visualize an input text synopsis. For this purpose,
              we collect the <a herf="https://ruc-aimind.github.io/projects/tevis.html">MovieNet-TeViS</a> benchmark based on
              the public <a target="_blank" rel="noopener" href="https://movienet.github.io/">MovieNet</a> dataset. <br/>
              
              Our collected MovieNet-TeViS dataset consists of 10,000 pairs of a synopsis sentence in English and a video storyboard, 
              i.e., a sequence of keyframes as our final dataset.  There are 45,584 keyframes in total. 
              The number of keyframes in a storyboard ranges from 3 to 11 and about 60\% storyboards consist of 3 or 4 keyframes. 
              The average number of words in a synopsis sentence is about 24. <br/>
              
              Tab. 1 presents the comparison of our dataset and related movie datasets. 
              It shows that the duration of movie clips corresponding to a description in LSMDC and MAD is only 4 seconds 
              and the average number of words in a description is only 9-12, which is much lower than ours. 
              It is impossible to extract a meaningful storyboard from such short clips. 
              Our MovieNet-TeViS and CMD give a synopsis or summary of 64-second or 132-second video segments respectively. 
              Thus we can expect the text in CMD is higher-level than that in ours, which is proved by lower avgConcreteness 
              (Please read our paper for more details). 
              Compared to CMD, our MovieNet-Tevis uses more words to describe video segments with half the duration of CMD. 
              This indicates that our text synopses provide more details than those in CMD. 
              As a start of such a challenging new task, 
              our dataset is the most appropriate in duration of video clip and semantic level of text.
            </p>
            <img class="ui fluid image" src="assets/img/dataset_tab.png" width="80%" />
          </div>
        </div>
      </div>
    </div>

    <div class="ui vertical stripe segment">
      <div class="ui middle aligned stackable grid container">
        <h1 class="ui header">Two Evaluation Subtasks</h1>
        <p>We design two evaluation settings for the TeViS task: <br/>
          1.	Ordering the Shuffled Keyframes Subtask:<br/>
          For a given text synopsis and its shuffled ground-truth images, 
          how well can the models order them? To measure the long-term reasoning capability of models for ordering, 
          we let the models order the ground-truth images and apply <i>Kendall' &tau;</i> to evaluate 
          how well the ordered list matches with the ground-truth list.<br/>
          2.	Retrieve-and-Ordering Keyframes Subtask:<br/>
          For a given text synopsis, how well can the models select the relevant images from a large set of candidates 
          and then order them? This task is more practical in real situations. 
          For this evaluation, we are given a text synopsis and a large set of candidate images. 
          The candidate images contain ground-truth images annotated by humans, 
          and other negative images which are randomly sampled from other images in the corpus. 
          The number of candidates including ground-truth and negative samples is 500. 
          We consider both retrieval and ordering performance and apply the product of <i>Recall@K</i> 
          and <i>Kendall' &tau;</i> as the final metric of this subtask. 
          Here the <i>Kendall' &tau;</i> is calculated upon the returned ground-truth images at top K only.
        </p>
      </div>
    </div>


    <div class="ui vertical stripe segment">
      <div class="ui middle aligned stackable grid container">
        <h1 class="ui header">Baseline Models</h1>
        <p>To provide a start point for tackling the task, 
          we propose a text-to-image retrieval module based on a pre-trained image-text model, 
          and an encoder-decoder module for ordering images. 
          A coherence-aware pre-training method is further proposed to leverage large-scale movies to improve coherence across frames for the ordering module. 
          The framework of our Trans-TeViS model for the TeViS task is shown in Fig. 4.
        </p>
        <img class="ui fluid image" src="assets/img/model.png" width="80%" />
        <p>In addition to the proposed Trans-TeViS model, we design three strong baselines based on CLIP for ordering as shown in Fig. 5:
        </p>
        <img class="ui fluid image" src="assets/img/clip_baseline.png" width="45%" />
      </div>
    </div>

    <div class="ui vertical stripe segment">
      <div class="ui middle aligned stackable grid container">
        <h1 class="ui header">Experimental Results</h1>
        <p>
          Qualitative examples of different models for the ordering task on our Movie-TeViS dataset.
          The <i>kendall' &tau;</i> metrics of our approach for Ordering Task and Retrieve-and-Order Task are shown in Tab. 2 and Tab. 4. 
          To learn more details, please refer to our <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2301.00135">paper</a>..
        </p>

        <img class="ui fluid image" src="assets/img/res.png" width="80%"/>

        <br/>
        <br/>

        <img class="ui fluid image" src="assets/img/task_all.png" width="80%"/>

        <p>
          Nevertheless, there is still a large gap compared to human performance suggesting room for promising future work.
        </p>
      </div>
    </div>


    <div class="ui vertical stripe segment" id="bib">
      <div class="ui middle aligned stackable grid container">
        <h1 class="ui header ">BibTeX</h1>

        <div class="ui center aligned container segment">
          <p>  
            @article{lin2023tiktalk,<br />
              &emsp;title={TikTalk: A Multi-Modal Dialogue Dataset for Real-World Chitchat},<br />
              &emsp;author={Lin, Hongpeng and Ruan, Ludan and Xia, Wenke and Liu, Peiyu and Wen, Jingyuan and Xu, Yixin and Hu, Di and Song, Ruihua and Zhao, Wayne Xin and Jin, Qin and others},<br />
              &emsp;journal={arXiv preprint arXiv:2301.05880},<br />
              &emsp;year={2023}<br />
            }
          </p>
        </div>
      </div>
    </div>

  </div>
      
  <!-- Footer -->
  <footer style="background-color:#373435ff;">
    <div class="container">
      <div style=" text-align:center;">
          <span class="copyright" style="color:#eee;" >Copyright &copy; 2023 AIMind All rights Reserved.</span>
      </div>
    </div>
  </footer>

    
</body>

</html>

        
  </div>
</article>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2022-2023
    AIMind All rights Reserved.
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
